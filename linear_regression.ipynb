{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35277f9d-789e-4885-ba17-1a11ac718162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Loading data\n",
    "df = pd.read_csv(\"housing.csv\")\n",
    "df_encoded = pd.get_dummies(df, columns=[\"ocean_proximity\"]) #Encoding \"ocean proximity\" column to integers\n",
    "df_filled = df_encoded.fillna(df_encoded.median()) #Filling NaN values with the column's median\n",
    "df_shuffled = df_filled.sample(frac=1, random_state=100) #Shuffling the dataset to prevent bias\n",
    "\n",
    "data = (df_shuffled.to_numpy()).astype(float) #Converting the dataframe to an array\n",
    "\n",
    "rows = data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d45b58-fa56-4193-ba34-c7bdfe56a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = data[0:int((0.8*rows)),:] #Using 80% of the data for training\n",
    "\n",
    "target = (training_data[:,8]).astype(float) #Extracting the target\n",
    "y = target_scaled = target / 1e5 #Scaling the target\n",
    "\n",
    "features = np.hstack((training_data[:, :8], training_data[:, 9:])) #Extracting the features\n",
    "training_mean = features.mean(axis = 0)\n",
    "training_std = features.std(axis = 0)\n",
    "training_std[training_std == 0] = 1\n",
    "x = features_scale = ((features - training_mean) / training_std) #Scaling the features\n",
    "\n",
    "weights = (np.random.rand(features.shape[1]))*0.01 #Randomizing initial weights\n",
    "\n",
    "bias = 0.0 #Initial bias = 0\n",
    "\n",
    "learning_rate = 0.005 #learning rate\n",
    "epochs = 2000 #number of loops\n",
    "\n",
    "loss_history = [] #To track the loss function\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    y_predicted = x @ weights + bias #Regression equation\n",
    "    loss = np.mean((y_predicted - y)**2) #Loss function\n",
    "    loss_history.append(loss) #Updating the loss function tracker\n",
    "\n",
    "    grad_w = (2/x.shape[0]) * x.T @ (y_predicted - y) #Gradient wrt weights\n",
    "    grad_b = (2/x.shape[0]) * np.sum(y_predicted - y) #Gradient wrt bias\n",
    "    \n",
    "    weights -= learning_rate*grad_w #Updating weights\n",
    "    bias -= learning_rate*grad_b #Updating bias\n",
    "\n",
    "    if epoch > 1 and abs(loss_history[-2] - loss_history[-1]) < 1e-5:\n",
    "        print(f\"Early stopping at epoch {epoch}\")\n",
    "        break\n",
    "\n",
    "y_predicted_real = y_predicted * 1e5 #Rescaling\n",
    "\n",
    "rmse = np.sqrt(np.mean((y_predicted_real - target)**2))\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "\n",
    "mae = np.mean(np.abs(y_predicted_real - target))\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "\n",
    "ss_res = np.sum((target - y_predicted_real) ** 2)\n",
    "ss_tot = np.sum((target - np.mean(target)) ** 2)\n",
    "r2 = 1 - (ss_res / ss_tot)\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ba1e81-c6da-4438-b73d-93e3fe3f8a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data[int(0.8*rows):,:].astype(float) #Using the rest of the data (20%) for testing\n",
    "\n",
    "test_features = np.hstack((test_data[:, :8], test_data[:, 9:])).astype(float) #Extracting features\n",
    "X = test_features_scales = ((test_features - training_mean) / training_std) #Scaling features\n",
    "\n",
    "test_target = (test_data[:,8]).astype(float) #Extracting the target\n",
    "y = test_target_scaled = test_target / 1e5 #Scaling the target\n",
    "\n",
    "#final_weights = weights\n",
    "#final_bias = bias\n",
    "\n",
    "y_predicted_test = X@weights + bias #Regression quation\n",
    "y_rescaled = y_predicted_test * 1e5 #Rescaling\n",
    "\n",
    "rmse = np.sqrt(np.mean((y_rescaled - test_target)**2))\n",
    "print(\"RMSE indicates the average magnitude of error between actual and predicted values\")\n",
    "print(f\"RMSE: {rmse:.2f}\\n\")\n",
    "\n",
    "mae = np.mean(np.abs(y_rescaled - test_target))\n",
    "print(\"MAE calculates the average of the absolute differences between actual and predicted values\")\n",
    "print(f\"MAE: {mae:.2f}\\n\")\n",
    "\n",
    "ss_res = np.sum((test_target - y_rescaled) ** 2)\n",
    "ss_tot = np.sum((test_target - np.mean(test_target)) ** 2)\n",
    "r2 = 1 - (ss_res / ss_tot)\n",
    "print(\"R² score indicates how well the model fits the data\")\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc80cbe5-c546-4a28-96d7-3e3fa845ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(loss_history, label='Training Loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
